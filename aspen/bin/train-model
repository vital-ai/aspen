#!/usr/bin/env groovy

import static groovy.io.FileType.FILES

def homeDir = new File(getClass().protectionDomain.codeSource.location.path).parentFile.parentFile.getAbsolutePath() + '/';

def mainClass = 'ai.vital.aspen.analysis.training.ModelTrainingJob'

if ( ! System.getenv('SPARK_HOME') ) {
	System.err.println("No SPARK_HOME environment variable set!");
	return
}

def sparkhome = System.getenv('SPARK_HOME')

//def sparkAssembly = new File(sparkhome, 'lib/spark-assembly-2.1.1-hadoop2.7.0.jar')

//if ( ! sparkAssembly.exists() ) {
//  System.err.println("Spark assemly jar not found: " + sparkAssembly.absolutePath);
//  return
//}

List jars = []

new File(homeDir, "target").eachFile(FILES) {
  if(it.name.matches("aspen\\-(jobs\\-)?\\d+\\.\\d+\\.\\d+\\.jar")) {
    jars.add(it.absolutePath)
  }
}

//jars.add( sparkAssembly.absolutePath )


new File(sparkhome, "jars").eachFile(FILES) {
  if(it.name.matches("(.*)\\.jar")) {
    jars.add(it.absolutePath)
  }
}

new File(homeDir, "libs").eachFile(FILES) {
  if(it.name.matches("(.*)\\.jar")) {
    jars.add(it.absolutePath)
  }
}



List cmd = ['java', '-Xmx32G', '-cp', (String)jars.join(File.pathSeparator), mainClass];

for(String a : args) {
	cmd.add(a);
}

println(cmd);

def process = new ProcessBuilder(cmd).redirectErrorStream(true).start()
process.inputStream.eachLine {println it}
